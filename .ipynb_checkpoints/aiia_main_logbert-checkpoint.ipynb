{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save options parameters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from logbert.bert_pytorch import Predictor, Trainer\n",
    "from logbert.bert_pytorch.dataset import WordVocab\n",
    "from common import Utils\n",
    "\n",
    "\n",
    "# define options\n",
    "options=dict()\n",
    "\n",
    "\n",
    "options[\"model_name\"] = \"logbert\"\n",
    "options[\"dataset_name\"] = \"aiia\"\n",
    "options[\"device\"] = \"cuda\"\n",
    "options[\"output_dir\"] = \"~/.output/\"\n",
    "options[\"model_dir\"] = \"logbert_aiia/\"\n",
    "\n",
    "options[\"train_ratio\"] = 1\n",
    "options[\"valid_ratio\"] = 0.1\n",
    "options[\"test_ratio\"] = 1\n",
    "\n",
    "options[\"max_epoch\"] = 200\n",
    "options[\"n_epochs_stop\"] = 5\n",
    "options[\"n_warm_up_epoch\"] = 0\n",
    "options[\"batch_size\"] = 32\n",
    "options[\"lr\"] = 0.001\n",
    "\n",
    "options[\"is_logkey\"] = True\n",
    "options[\"is_time\"] = False\n",
    "options[\"min_freq\"] = 1\n",
    "\n",
    "options[\"seq_len\"] = 512\n",
    "options[\"min_len\"] = 10\n",
    "options[\"max_len\"] = 512\n",
    "options[\"mask_ratio\"] = 0.5\n",
    "\n",
    "options[\"window_size\"] = 20\n",
    "options[\"adaptive_window\"] = True\n",
    "options[\"deepsvdd_loss\"] = False\n",
    "options[\"deepsvdd_loss_test\"] = False\n",
    "\n",
    "options[\"scale\"] = None\n",
    "options[\"scale_path\"] = None\n",
    "options[\"hidden\"] = 256\n",
    "options[\"layers\"] = 4\n",
    "\n",
    "options[\"attn_heads\"] = 4\n",
    "options[\"num_workers\"] = 5\n",
    "options[\"adam_beta1\"] = 0.9\n",
    "options[\"adam_beta2\"] = 0.999\n",
    "options[\"adam_weight_decay\"] = 0.00\n",
    "options[\"log_freq\"] = 100\n",
    "options[\"num_candidates\"] = 15\n",
    "\n",
    "\n",
    "options[\"output_dir\"] = os.path.expanduser(options[\"output_dir\"] + options[\"dataset_name\"] + \"/\")\n",
    "options[\"model_dir\"] = options[\"output_dir\"] + options[\"model_dir\"]\n",
    "\n",
    "options[\"train_vocab\"] = options[\"output_dir\"] + \"train\"\n",
    "options[\"vocab_path\"] = options[\"output_dir\"] + \"vocab.pkl\"  # pickle file\n",
    "options[\"model_path\"] = options[\"model_dir\"] + \"best_model.pth\"\n",
    "options[\"scale_path\"] = options[\"model_dir\"] + \"scale.pkl\"\n",
    "\n",
    "options[\"testset_files\"] = [\"evalue-\"+str(i)+\".txt.test\" for i in range(0,10)]\n",
    "\n",
    "if not os.path.exists(options[\"model_dir\"]):\n",
    "    os.makedirs(options[\"model_dir\"], exist_ok=True)\n",
    "\n",
    "Utils.seed_everything(seed=1234)\n",
    "\n",
    "print(\"Save options parameters\")\n",
    "Utils.save_parameters(options, options[\"model_dir\"] + \"parameters.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(options[\"vocab_path\"]):\n",
    "    with open(options[\"train_vocab\"], \"r\") as f:\n",
    "        texts = f.readlines()\n",
    "    vocab = WordVocab(texts, min_freq=options[\"min_freq\"])\n",
    "    print(\"VOCAB SIZE:\", len(vocab))\n",
    "    print(\"save vocab in\", options[\"vocab_path\"])\n",
    "    print(\"\\n\")\n",
    "    vocab.save_vocab(options[\"vocab_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3066/36855 [00:00<00:01, 30653.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab /root/.output/aiia/vocab.pkl\n",
      "vocab Size:  261\n",
      "before filtering short session\n",
      "train size  33170\n",
      "valid size  3685\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36855/36855 [00:01<00:00, 30533.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Num of train seqs 33170\n",
      "Num of valid seqs 3685\n",
      "========================================\n",
      "Building BERT model\n",
      "Creating BERT Trainer\n",
      "True\n",
      "Total Parameters: 2243846\n",
      "Training Start\n",
      "\n",
      "\n",
      "Epoch: 0 | phase: train, loss=2.990953335775832\n",
      "logkey loss: 2.990953335775832, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 0 | phase: valid, loss=1.5545365800028261\n",
      "logkey loss: 1.5545365800028261, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 1 | phase: train, loss=1.249563146051753\n",
      "logkey loss: 1.249563146051753, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 1 | phase: valid, loss=0.9906563567078632\n",
      "logkey loss: 0.9906563567078632, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 2 | phase: train, loss=0.839844182191208\n",
      "logkey loss: 0.839844182191208, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 2 | phase: valid, loss=0.6998442209285238\n",
      "logkey loss: 0.6998442209285238, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 3 | phase: train, loss=0.623309621738421\n",
      "logkey loss: 0.623309621738421, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 3 | phase: valid, loss=0.5538363581118376\n",
      "logkey loss: 0.5538363581118376, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 4 | phase: train, loss=0.5131347623858673\n",
      "logkey loss: 0.5131347623858673, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 4 | phase: valid, loss=0.46403782238130986\n",
      "logkey loss: 0.46403782238130986, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 5 | phase: train, loss=0.43686028348433004\n",
      "logkey loss: 0.43686028348433004, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 5 | phase: valid, loss=0.40899452022884203\n",
      "logkey loss: 0.40899452022884203, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 6 | phase: train, loss=0.39454241680937846\n",
      "logkey loss: 0.39454241680937846, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 6 | phase: valid, loss=0.3688652900250062\n",
      "logkey loss: 0.3688652900250062, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 7 | phase: train, loss=0.3694875026157694\n",
      "logkey loss: 0.3694875026157694, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 7 | phase: valid, loss=0.3522108948749045\n",
      "logkey loss: 0.3522108948749045, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 8 | phase: train, loss=0.35161935421548296\n",
      "logkey loss: 0.35161935421548296, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 8 | phase: valid, loss=0.34435363748799197\n",
      "logkey loss: 0.34435363748799197, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n",
      "Epoch: 9 | phase: train, loss=0.3329942673588582\n",
      "logkey loss: 0.3329942673588582, deepsvdd loss: 0.0\n",
      "\n",
      "Epoch: 9 | phase: valid, loss=0.31505034708458446\n",
      "logkey loss: 0.31505034708458446, deepsvdd loss: 0.0\n",
      "\n",
      "Log saved\n",
      " Model Saved on: /root/.output/aiia/logbert_aiia/best_model.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Trainer(options).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictor(options).predict_aiia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Result','StartLineNum','Detail','TimeCost'])\n",
    "\n",
    "for i, testset_file in enumerate(options[\"testset_files\"]):\n",
    "    print(\"Now predicting \"+testset_file+\".\")\n",
    "    evaluefile_path = \"evalue/\" + testset_file\n",
    "\n",
    "    predict_result, elapsed_time = Predictor(options).predict_testset_aiia(evaluefile_path,seq_threshold=0.1)\n",
    "    new_row = {\"Result\":predict_result,\"StartLineNum\":2,\"Detail\":1,\"TimeCost\":elapsed_time}\n",
    "    result_df = result_df.append(new_row,ignore_index=True)\n",
    "\n",
    "result_df.to_csv(options[\"output_dir\"]+\"result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
