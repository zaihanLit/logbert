{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'regex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-794cb20de5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleParserFactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_train_test_aiia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_test_set_aiia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_raw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/logbert/dataset/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimple_parser_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleParserFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindowFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample_raw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_train_test_aiia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/logbert/dataset/simple_parser_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlogparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlogparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSimpleParserFactory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/logbert/logparser/Spell.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# import re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mregex\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'regex'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pipelines for processing raw logs to structured data\n",
    "including sampling (optional), log parsing, log sequence generation by windowing, and train test splitting\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from dataset import SimpleParserFactory, split_train_test_aiia, generate_test_set_aiia, sample_raw_data\n",
    "\n",
    "\n",
    "# define options\n",
    "options=dict()\n",
    "\n",
    "# directory path\n",
    "options[\"dataset_name\"] = \"aiia\"\n",
    "options[\"data_dir\"] = \"~/.dataset/\"\n",
    "options[\"output_dir\"] = \"~/.output/\"\n",
    "\n",
    "# log file name\n",
    "options[\"log_file\"] = \"normal.txt\"\n",
    "\n",
    "options[\"parser_type\"] = \"drain\"\n",
    "options[\"log_format\"] = \"Id,Content\"\n",
    "\n",
    "REGEX1='(0x)[0-9a-fA-F]+'\n",
    "REGEX2='\\d+.\\d+.\\d+.\\d+'\n",
    "REGEX3='(/[-\\w]+)+'\n",
    "REGEX4='\\d+'\n",
    "options[\"regex\"] = [REGEX1,REGEX2,REGEX3,REGEX4]\n",
    "options[\"keep_para\"] = False\n",
    "\n",
    "options[\"st\"] = 0.3\n",
    "options[\"depth\"] = 3\n",
    "options[\"max_child\"] = 100\n",
    "options[\"tau\"] = 0.5\n",
    "\n",
    "options[\"window_type\"] = \"sliding_aiia\"\n",
    "options[\"window_size\"] = 50\n",
    "options[\"step_size\"] = 5\n",
    "options[\"train_size\"] = 0.7\n",
    "\n",
    "# evalue logs\n",
    "options[\"evalue_files\"] = [\"evalue-\"+str(i)+\".txt\" for i in range(0,20)]\n",
    "\n",
    "# parser path\n",
    "options[\"parserPickle_path\"] = \"/root/.output/aiia/parser.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "# the main process\n",
    "options[\"output_dir\"] = os.path.expanduser(options[\"output_dir\"])\n",
    "options[\"data_dir\"] = os.path.expanduser(options[\"data_dir\"])\n",
    "\n",
    "options[\"data_dir\"] = os.path.join(options[\"data_dir\"], options[\"dataset_name\"] + \"/\")\n",
    "options[\"output_dir\"] = os.path.join(options[\"output_dir\"], options[\"dataset_name\"] + \"/\")\n",
    "\n",
    "\n",
    "if not os.path.exists(options[\"output_dir\"]):\n",
    "    os.makedirs(options[\"output_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parse normal logs\n",
    "if options[\"parser_type\"] is not None:\n",
    "    options[\"log_format\"] = \" \".join([f\"<{field}>\" for field in options[\"log_format\"].split(\",\")])\n",
    "    parser = SimpleParserFactory.create_parser(options[\"data_dir\"], options[\"output_dir\"], options[\"parser_type\"], options[\"log_format\"],\n",
    "                                                options[\"regex\"], options[\"keep_para\"],\n",
    "                                                options[\"st\"], options[\"depth\"], options[\"max_child\"], options[\"tau\"])\n",
    "    parser.parse(options[\"log_file\"])\n",
    "\n",
    "    with open(options[\"parserPickle_path\"], \"wb\") as f:\n",
    "        pickle.dump(parser, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split normal to train and valid set\n",
    "\n",
    "split_train_test_aiia(data_dir=options[\"data_dir\"],\n",
    "                    output_dir=options[\"output_dir\"],\n",
    "                    log_file=options[\"log_file\"],\n",
    "                    dataset_name=options[\"dataset_name\"],\n",
    "                    window_type=options[\"window_type\"],\n",
    "                    window_size=options[\"window_size\"],\n",
    "                    step_size=options[\"step_size\"],\n",
    "                    train_size=options[\"train_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse evalue logs\n",
    "with open(options[\"parserPickle_path\"], \"rb\") as f:\n",
    "    parser = pickle.load(f)\n",
    "\n",
    "for evalue_file in options[\"evalue_files\"]:\n",
    "    print(\"Now processing \"+evalue_file+\".\")\n",
    "    evaluefile_path = \"evalue/\" + evalue_file\n",
    "\n",
    "    options[\"log_format\"] = \" \".join([f\"<{field}>\" for field in options[\"log_format\"].split(\",\")])\n",
    "    parser.parse(evaluefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test set for each evalue files\n",
    "\n",
    "for evalue_file in options[\"evalue_files\"]:\n",
    "    print(\"Now processing \"+evalue_file+\".\")\n",
    "    evaluefile_path = \"evalue/\" + evalue_file\n",
    "\n",
    "    generate_test_set_aiia(output_dir=options[\"output_dir\"],\n",
    "                        log_file=evaluefile_path,\n",
    "                        window_type=options[\"window_type\"],\n",
    "                        window_size=options[\"window_size\"],\n",
    "                        step_size=options[\"step_size\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5",
   "language": "python",
   "name": "torch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
